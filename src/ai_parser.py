# src/ai_parser.py

import requests
import json
import re

# å®šä¹‰Ollama APIçš„åœ°å€å’Œæ¨¡å‹åç§°
OLLAMA_API_URL = "http://localhost:11434/api/chat"

"""
    NAME                 ID              SIZE      MODIFIED
    qwen2.5-coder:14b    9ec8897f747e    9.0 GB    4 minutes ago
    qwen2.5-coder:7b     dae161e27b0e    4.7 GB    14 minutes ago
    deepseek-r1:14b      c333b7232bdb    9.0 GB    2 hours ago
    deepseek-r1:7b       755ced02ce7b    4.7 GB    2 hours ago
    llama3:8b            365c0bd3c000    4.7 GB    16 hours ago
"""

MODEL_NAME = "qwen2.5-coder:7b"
SYSTEM_PROMPT_FILE = "prompts/system_prompt.txt"

def split_command_into_chunks(user_command: str, max_chunks: int = 5):
    """
        å°†ç”¨æˆ·çš„é•¿æŒ‡ä»¤åˆ†å‰²æˆæ›´å°çš„ã€ç¬¦åˆé€»è¾‘çš„å—ã€‚

        ä¸ºä»€ä¹ˆè¿™ä¹ˆåšï¼Ÿ
        - æˆ‘ä»¬å‘ç°ï¼Œä¸€æ¬¡æ€§å°†ä¸€ä¸ªéå¸¸é•¿çš„æŒ‡ä»¤ï¼ˆä¾‹å¦‚ï¼ŒåŒ…å«10ä¸ªæ­¥éª¤ï¼‰äº¤ç»™ä¸€ä¸ª7Bå¤§å°çš„æ¨¡å‹ï¼Œ
          å®ƒå¾ˆå®¹æ˜“åœ¨ç”ŸæˆJSONçš„è¿‡ç¨‹ä¸­â€œå¿˜è®°â€å‰é¢çš„æŒ‡ä»¤ï¼Œæˆ–è€…æœ€ç»ˆçš„JSONç»“æ„ä¼šéå¸¸æ··ä¹±ã€‚
        - é€šè¿‡å°†æŒ‡ä»¤æŒ‰è‡ªç„¶è¯­è¨€çš„æ¢è¡Œç¬¦ï¼ˆä»£è¡¨ä¸€ä¸ªç‹¬ç«‹çš„æ­¥éª¤ï¼‰åˆ†å‰²ï¼Œæˆ‘ä»¬å¯ä»¥ä¸€æ¬¡åªè®©æ¨¡å‹ä¸“æ³¨äºä¸€ä¸ªå­ä»»åŠ¡ã€‚
          è¿™å°±åƒæˆ‘ä»¬æŒ‡å¯¼æ–°æ‰‹ä¸€æ ·ï¼Œä¸€æ­¥ä¸€æ­¥æ¥ï¼Œè€Œä¸æ˜¯ä¸€æ¬¡æ€§å‘Šè¯‰ä»–æ‰€æœ‰äº‹æƒ…ã€‚

        Args:
            user_command (str): ç”¨æˆ·çš„å®Œæ•´è‡ªç„¶è¯­è¨€æŒ‡ä»¤ã€‚
            max_chunks (int): ä¸ºäº†é˜²æ­¢æŒ‡ä»¤è¢«è¿‡åº¦åˆ†å‰²ï¼ˆä¾‹å¦‚ï¼Œä¸€ä¸ªè¡¨æ ¼çš„æ¯ä¸€è¡Œéƒ½è¢«åˆ†å¼€ï¼‰ï¼Œ
                              æˆ‘ä»¬è®¾ç½®ä¸€ä¸ªæœ€å¤§åˆ†å—æ•°ã€‚è¶…è¿‡è¿™ä¸ªæ•°é‡ï¼Œåé¢çš„å†…å®¹ä¼šåˆå¹¶åˆ°æœ€åä¸€ä¸ªå—ä¸­ã€‚

        Returns:
            list[str]: ä¸€ä¸ªåŒ…å«æŒ‡ä»¤å—å­—ç¬¦ä¸²çš„åˆ—è¡¨ã€‚
        """
    # 1. ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æŒ‰ä¸€ä¸ªæˆ–å¤šä¸ªæ¢è¡Œç¬¦è¿›è¡Œåˆ†å‰²
    lines = re.split(r'\n\s*\n*', user_command.strip())
    # 2. è¿‡æ»¤æ‰æ‰€æœ‰ä»…åŒ…å«ç©ºç™½å­—ç¬¦çš„æ— æ•ˆè¡Œ
    chunks = [chunk.strip() for chunk in lines if chunk.strip()]

    # 3. å¦‚æœåˆ†å‰²åçš„å—æ•°è¶…è¿‡äº†æœ€å¤§é™åˆ¶
    if len(chunks) > max_chunks:
        print(f"è­¦å‘Šï¼šæŒ‡ä»¤è¢«åˆ†å‰²æˆ {len(chunks)} å—ï¼Œè¶…è¿‡æœ€å¤§é™åˆ¶ {max_chunks}ã€‚")
        # å°†è¶…å‡ºçš„éƒ¨åˆ†åˆå¹¶åˆ°æœ€åä¸€ä¸ªå—ä¸­
        last_valid_chunk = "\n".join(chunks[max_chunks - 1:])
        chunks = chunks[:max_chunks - 1] + [last_valid_chunk]
        print(f"å·²å°†æŒ‡ä»¤åˆå¹¶ä¸º {len(chunks)} å—è¿›è¡Œå¤„ç†ã€‚")

    return chunks


def parse_natural_language_to_json(user_command: str) -> dict | None:
    """
        å°†ç”¨æˆ·çš„è‡ªç„¶è¯­è¨€æŒ‡ä»¤å‘é€ç»™æœ¬åœ°LLMï¼Œå¹¶è§£æè¿”å›çš„JSONã€‚
    æ­¤å‡½æ•°ç°åœ¨æ”¯æŒå°†é•¿æŒ‡ä»¤åˆ†å—ï¼Œä»¥æé«˜ç¨³å®šæ€§å’Œå¤„ç†å¤æ‚æŒ‡ä»¤çš„èƒ½åŠ›ã€‚

    Args:
        user_command (str): ç”¨æˆ·çš„è‡ªç„¶è¯­è¨€æŒ‡ä»¤ã€‚

    Returns:
        dict | None: è§£ææˆåŠŸåˆ™è¿”å›åŒ…å«æ–‡æ¡£ç»“æ„çš„å­—å…¸ï¼Œå¦åˆ™è¿”å›Noneã€‚
    """

    # 1.è¯»å–æˆ‘ä»¬çš„â€œpromptâ€
    try:
        with open(SYSTEM_PROMPT_FILE, 'r', encoding='utf-8') as f:
            system_prompt = f.read()
    except FileNotFoundError:
        print(f"é”™è¯¯ï¼šç³»ç»Ÿæç¤ºæ–‡ä»¶æœªæ‰¾åˆ° -> {SYSTEM_PROMPT_FILE}")
        return None

    # 2. å°†ç”¨æˆ·çš„å®Œæ•´æŒ‡ä»¤åˆ†å‰²æˆå¤šä¸ªå—
    chunks = split_command_into_chunks(user_command)

    # åˆå§‹åŒ–ä¸€ä¸ªæœ€ç»ˆçš„JSONå¯¹è±¡å’Œæ‰€æœ‰å…ƒç´ çš„åˆ—è¡¨
    aggregated_document_data = {
        "elements": []
    }

    print(f"ğŸ§  æŒ‡ä»¤å·²è¢«åˆ†ä¸º {len(chunks)} ä¸ªä»»åŠ¡å—ï¼Œå¼€å§‹é€ä¸€è°ƒç”¨AIè§£æå™¨...")

    for i, chunk in enumerate(chunks):
        print(f"\n--- æ­£åœ¨å¤„ç†ç¬¬ {i + 1}/{len(chunks)} ä¸ªä»»åŠ¡å— ---")
        print(f"æŒ‡ä»¤å†…å®¹: \"{chunk}\"")
        # 4. ä¸ºæ¯ä¸ªå—æ„å»ºç‰¹å®šçš„è¯·æ±‚
        chunk_user_prompt = f"""
        This is part {i + 1} of a multi-part command.
        The user's command for THIS part is: "{chunk}"
        CONTEXT: So far, the following number of elements have been generated: {len(aggregated_document_data['elements'])}. 
        Please generate the JSON structure ONLY for the command in THIS part. Do not repeat or re-generate previous elements."""

        payload = {
            "model": MODEL_NAME,
            "messages": [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": chunk_user_prompt}
            ],
            "format": "json",
            "stream": False
        }

        # 3. å‘é€HTTP POSTè¯·æ±‚
        try:
            response = requests.post(OLLAMA_API_URL, json=payload, timeout=60)
            response.raise_for_status() # å¦‚æœHTTPçŠ¶æ€ç æ˜¯4xxæˆ–5xxï¼Œåˆ™æŠ›å‡ºå¼‚å¸¸
            # è§£æè¿”å›çš„å“åº”
            response_data = response.json()
            message_content = response_data.get('message', {}).get('content')

            if not message_content:
                print(f"é”™è¯¯ï¼šç¬¬ {i + 1} ä¸ªå—çš„AIå“åº”ä¸­æ‰¾ä¸åˆ°å†…å®¹ã€‚")
                return None

            # è§£æå½“å‰å—è¿”å›çš„JSONç‰‡æ®µ
            chunk_json = json.loads(message_content)

            print(f"--- AIä¸ºå— {i + 1} è¿”å›çš„JSONç‰‡æ®µ ---")
            print(json.dumps(chunk_json, indent=2, ensure_ascii=False))
            print("--------------------------------")

            # 6. JSONèšåˆï¼šå°†æ–°ç”Ÿæˆçš„å…ƒç´ åˆå¹¶åˆ°æœ€ç»ˆç»“æœä¸­
            #    è¿™æ˜¯æ•´ä¸ªæµç¨‹çš„å…³é”®ä¸€æ­¥ï¼Œæˆ‘ä»¬å°†æ‰€æœ‰â€œé›¶ä»¶â€ç»„è£…æˆä¸€ä¸ªå®Œæ•´çš„äº§å“ã€‚
            new_elements = chunk_json.get('elements', [])
            if new_elements:
                aggregated_document_data['elements'].extend(new_elements)
                print(f"âœ… æˆåŠŸèšåˆ {len(new_elements)} ä¸ªæ–°å…ƒç´ ã€‚")

            # åŒæ—¶ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰é¡µé¢è®¾ç½®ï¼Œå¹¶æ›´æ–°åˆ°ä¸»å¯¹è±¡ä¸­
            # è¿™å…è®¸ç”¨æˆ·åœ¨ä»»ä½•æ­¥éª¤ä¸­è®¾ç½®é¡µé¢æ ¼å¼
            if 'page_setup' in chunk_json:
                # ä½¿ç”¨.update()å¯ä»¥åˆå¹¶å­—å…¸ï¼Œæˆ–æ·»åŠ æ–°é”®
                if 'page_setup' not in aggregated_document_data:
                    aggregated_document_data['page_setup'] = {}
                aggregated_document_data['page_setup'].update(chunk_json['page_setup'])
                print("âœ… å·²æ›´æ–°é¡µé¢è®¾ç½®ã€‚")


        except requests.exceptions.RequestException as e:
            print(f"é”™è¯¯ï¼šåœ¨å¤„ç†ç¬¬ {i + 1} ä¸ªå—æ—¶è¿æ¥Ollama APIå¤±è´¥ -> {e}")
            return None
        except json.JSONDecodeError as e:
            print(f"é”™è¯¯ï¼šåœ¨å¤„ç†ç¬¬ {i + 1} ä¸ªå—æ—¶AIè¿”å›çš„ä¸æ˜¯æœ‰æ•ˆçš„JSONæ ¼å¼ -> {e}")
            print(f"æ”¶åˆ°çš„å†…å®¹: {message_content}")
            return None

    print("\nâœ… æ‰€æœ‰ä»»åŠ¡å—å¤„ç†å®Œæ¯•ï¼ŒAIè§£ææˆåŠŸï¼")
    return aggregated_document_data



# --- æµ‹è¯•ä»£ç  ---
if __name__ == "__main__":

    test_command = """
    ç»™æˆ‘ä¸€ä¸ªä¸€çº§æ ‡é¢˜å«'é”€å”®æŠ¥å‘Š'ã€‚
    ç„¶åå¦èµ·ä¸€æ®µï¼Œå†…å®¹æ˜¯'è¿™æ˜¯ç¬¬ä¸€å­£åº¦çš„æ€»ç»“'ï¼Œå®‹ä½“å°å››ï¼Œé¦–è¡Œç¼©è¿›ã€‚
    æœ€åï¼Œç»™æˆ‘ä¸€ä¸ª3x3çš„è¡¨æ ¼ï¼Œå¸¦è¡¨å¤´ï¼Œå†…å®¹æ˜¯å§“åã€å¹´é¾„ã€åŸå¸‚ï¼Œå¼ ä¸‰ã€30ã€åŒ—äº¬ï¼Œæå››ã€25ã€ä¸Šæµ·ã€‚ç¬¬ä¸€åˆ—å·¦å¯¹é½ï¼Œåä¸¤åˆ—å±…ä¸­ã€‚
    """

    document_structure = parse_natural_language_to_json(test_command)
    if document_structure:
        print("\n--- è§£æå¾—åˆ°çš„JSONç»“æ„ ---")
        print(json.dumps(document_structure, indent=2, ensure_ascii=False))


