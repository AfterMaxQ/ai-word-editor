# src/ai_parser.py

from http.client import responses

import requests
import json

# å®šä¹‰Ollama APIçš„åœ°å€å’Œæ¨¡å‹åç§°
OLLAMA_API_URL = "http://localhost:11434/api/chat"

"""
    NAME                 ID              SIZE      MODIFIED
    qwen2.5-coder:14b    9ec8897f747e    9.0 GB    4 minutes ago
    qwen2.5-coder:7b     dae161e27b0e    4.7 GB    14 minutes ago
    deepseek-r1:14b      c333b7232bdb    9.0 GB    2 hours ago
    deepseek-r1:7b       755ced02ce7b    4.7 GB    2 hours ago
    llama3:8b            365c0bd3c000    4.7 GB    16 hours ago
"""

MODEL_NAME = "qwen2.5-coder:14b"
SYSTEM_PROMPT_FILE = "prompts/system_prompt.txt"

def parse_natural_language_to_json(user_command: str) -> dict | None:
    """
        å°†ç”¨æˆ·çš„è‡ªç„¶è¯­è¨€æŒ‡ä»¤å‘é€ç»™æœ¬åœ°LLMï¼Œå¹¶è§£æè¿”å›çš„JSONã€‚

        Args:
            user_command (str): ç”¨æˆ·çš„è‡ªç„¶è¯­è¨€æŒ‡ä»¤ã€‚

        Returns:
            dict | None: è§£ææˆåŠŸåˆ™è¿”å›åŒ…å«æ–‡æ¡£ç»“æ„çš„å­—å…¸ï¼Œå¦åˆ™è¿”å›Noneã€‚
    """
    print("ğŸ§  æ­£åœ¨è°ƒç”¨AIè§£æå™¨ï¼Œè¯·ç¨å€™...")

    # 1.è¯»å–æˆ‘ä»¬çš„â€œpromptâ€
    try:
        with open(SYSTEM_PROMPT_FILE, 'r', encoding='utf-8') as f:
            system_prompt = f.read()
    except FileNotFoundError:
        print(f"é”™è¯¯ï¼šç³»ç»Ÿæç¤ºæ–‡ä»¶æœªæ‰¾åˆ° -> {SYSTEM_PROMPT_FILE}")
        return None

    # 2. æ„å»ºå‘é€ç»™Ollama APIçš„æ•°æ®è½½è· (Payload)
    payload = {
        "model": MODEL_NAME,
        "messages":[
            {"role":"system", "content": system_prompt},
            {"role":"user", "content": user_command}
        ],
        "format": "json",
        "stream": False
    }

    # 3. å‘é€HTTP POSTè¯·æ±‚
    try:
        response = requests.post(OLLAMA_API_URL, json=payload, timeout=60)
        response.raise_for_status() # å¦‚æœHTTPçŠ¶æ€ç æ˜¯4xxæˆ–5xxï¼Œåˆ™æŠ›å‡ºå¼‚å¸¸
        # è§£æè¿”å›çš„å“åº”
        response_data = response.json()

        # 1. (è°ƒè¯•) æ‰“å°å‡ºOllamaè¿”å›çš„å®Œæ•´åŸå§‹JSONï¼Œè¿™å¯¹äºæ’é”™è‡³å…³é‡è¦ï¼
        print("--- Ollama Raw Response ---")
        print(json.dumps(response_data, indent=2, ensure_ascii=False))
        print("--------------------------")

        # 2. (ä¿®æ­£) ä½¿ç”¨æ–°çš„ã€æ›´å¥å£®çš„è§£æé€»è¾‘
        # æ–°ç‰ˆOllamaé€šå¸¸å°†å†…å®¹ç›´æ¥æ”¾åœ¨ response['message']['content']
        message_content = response_data.get('message', {}).get('content')

        if not message_content:
            print("é”™è¯¯ï¼šåœ¨Ollamaçš„å“åº”ä¸­æ‰¾ä¸åˆ°'message'æˆ–'content'ã€‚")
            return None

        # Ollamaè¿”å›çš„JSONå†…å®¹æœ¬èº«æ˜¯ä¸€ä¸ªå­—ç¬¦ä¸²ï¼Œéœ€è¦å†æ¬¡è§£æ
        parsed_json = json.loads(message_content)
        print("âœ… AIè§£ææˆåŠŸï¼")
        return parsed_json

    except requests.exceptions.RequestException as e:
        print(f"é”™è¯¯ï¼šè¿æ¥Ollama APIå¤±è´¥ -> {e}")
        print(f"è¯·ç¡®ä¿OllamaæœåŠ¡æ­£åœ¨åå°è¿è¡Œï¼Œå¹¶ä¸”æ¨¡å‹ '{MODEL_NAME}' å·²é€šè¿‡ `ollama pull` ä¸‹è½½ã€‚")
        return None
    except json.JSONDecodeError as e:
        # å¢åŠ å¯¹è§£æå¤±è´¥æ—¶å†…å®¹çš„æ‰“å°
        print(f"é”™è¯¯ï¼šAIè¿”å›çš„ä¸æ˜¯æœ‰æ•ˆçš„JSONæ ¼å¼ -> {e}")
        print(f"æ”¶åˆ°çš„å†…å®¹: {message_content}")
        return None

# --- æµ‹è¯•ä»£ç  ---
if __name__ == "__main__":

    test_command = """
    ç»™æˆ‘ä¸€ä¸ªä¸€çº§æ ‡é¢˜å«'é”€å”®æŠ¥å‘Š'ã€‚
    ç„¶åå¦èµ·ä¸€æ®µï¼Œå†…å®¹æ˜¯'è¿™æ˜¯ç¬¬ä¸€å­£åº¦çš„æ€»ç»“'ï¼Œå®‹ä½“å°å››ï¼Œé¦–è¡Œç¼©è¿›ã€‚
    æœ€åï¼Œç»™æˆ‘ä¸€ä¸ª3x3çš„è¡¨æ ¼ï¼Œå¸¦è¡¨å¤´ï¼Œå†…å®¹æ˜¯å§“åã€å¹´é¾„ã€åŸå¸‚ï¼Œå¼ ä¸‰ã€30ã€åŒ—äº¬ï¼Œæå››ã€25ã€ä¸Šæµ·ã€‚ç¬¬ä¸€åˆ—å·¦å¯¹é½ï¼Œåä¸¤åˆ—å±…ä¸­ã€‚
    """

    document_structure = parse_natural_language_to_json(test_command)
    if document_structure:
        print("\n--- è§£æå¾—åˆ°çš„JSONç»“æ„ ---")
        print(json.dumps(document_structure, indent=2, ensure_ascii=False))


